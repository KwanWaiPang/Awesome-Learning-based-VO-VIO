# Paper Survey for Learning-based VO, VIO, and IO
- [Learning-based VO](#Learning-based-VO)
- [Learning-based VIO](#Learning-based-VIO)
- [Learning-based IO](#Learning-based-IO)

## Learning-based VO

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2024|`RAL`|[Efficient Camera Exposure Control for Visual Odometry via Deep Reinforcement Learning](https://arxiv.org/pdf/2408.17005)|[![Github stars](https://img.shields.io/github/stars/ShuyangUni/drl_exposure_ctrl.svg)](https://github.com/ShuyangUni/drl_exposure_ctrl)|---| 
|2024|`ECCV`|[Reinforcement learning meets visual odometry](https://arxiv.org/pdf/2407.15626)|[![Github stars](https://img.shields.io/github/stars/uzh-rpg/rl_vo.svg)](https://github.com/uzh-rpg/rl_vo)|[Blog](https://kwanwaipang.github.io/RL-for-VO/)|
|2024|`IROS`|[Deep Visual Odometry with Events and Frames](https://arxiv.org/pdf/2309.09947)|[![Github stars](https://img.shields.io/github/stars/uzh-rpg/rampvo.svg)](https://github.com/uzh-rpg/rampvo)|---| 
|2024|`3DV`|[Deep event visual odometry](https://arxiv.org/pdf/2312.09800)|[![Github stars](https://img.shields.io/github/stars/tum-vision/DEVO.svg)](https://github.com/tum-vision/DEVO)|---|
|2024|`ECCV`|[Deep patch visual slam](https://arxiv.org/pdf/2408.01654)|[![Github stars](https://img.shields.io/github/stars/princeton-vl/DPVO.svg)](https://github.com/princeton-vl/DPVO)|---|
|2024|`NIPS`|[Deep patch visual odometry](https://proceedings.neurips.cc/paper_files/paper/2023/file/7ac484b0f1a1719ad5be9aa8c8455fbb-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/princeton-vl/DPVO.svg)](https://github.com/princeton-vl/DPVO)|---|
|2022|`Neurocomputing`|[DeepAVO: Efficient pose refining with feature distilling for deep Visual Odometry](https://arxiv.org/pdf/2105.09899)|---|---| 
|2021|`CoRL`|[Tartanvo: A generalizable learning-based vo](https://proceedings.mlr.press/v155/wang21h/wang21h.pdf)|[![Github stars](https://img.shields.io/github/stars/castacks/tartanvo.svg)](https://github.com/castacks/tartanvo)|---|
|2021|`NIPS`|[DROID-SLAM: Deep Visual SLAM for Monocular,Stereo, and RGB-D Cameras](https://proceedings.neurips.cc/paper/2021/file/89fcd07f20b6785b92134bd6c1d0fa42-Paper.pdf)|[![Github stars](https://img.shields.io/github/stars/princeton-vl/DROID-SLAM.svg)](https://github.com/princeton-vl/DROID-SLAM)|---|
|2021|`CVPR`|[Generalizing to the open world: Deep visual odometry with online adaptation](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Generalizing_to_the_Open_World_Deep_Visual_Odometry_With_Online_CVPR_2021_paper.pdf)|---|---|
|2021|`arXiv`|[DF-VO: What should be learnt for visual odometry?](https://arxiv.org/pdf/2103.00933)|[![Github stars](https://img.shields.io/github/stars/Huangying-Zhan/DF-VO.svg)](https://github.com/Huangying-Zhan/DF-VO)|---|
|2020|`ICRA`|[Visual odometry revisited: What should be learnt?](https://arxiv.org/pdf/1909.09803)|[![Github stars](https://img.shields.io/github/stars/Huangying-Zhan/DF-VO.svg)](https://github.com/Huangying-Zhan/DF-VO)|---|
|2020|`CVPR`|[Towards better generalization: Joint depth-pose learning without posenet](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_Towards_Better_Generalization_Joint_Depth-Pose_Learning_Without_PoseNet_CVPR_2020_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/B1ueber2y/TrianFlow.svg)](https://github.com/B1ueber2y/TrianFlow)|---|
|2020|`CVPR`|[Diffposenet: Direct differentiable camera pose estimation](https://openaccess.thecvf.com/content/CVPR2022/papers/Parameshwara_DiffPoseNet_Direct_Differentiable_Camera_Pose_Estimation_CVPR_2022_paper.pdf)|---|---| 
|2020|`CVPR`|[D3vo: Deep depth, deep pose and deep uncertainty for monocular visual odometry](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_D3VO_Deep_Depth_Deep_Pose_and_Deep_Uncertainty_for_Monocular_CVPR_2020_paper.pdf)|---|[website](https://cvg.cit.tum.de/research/vslam/d3vo)| 
|2021|`IJCV`|[Unsupervised scale-consistent depth learning from video](https://arxiv.org/pdf/2105.11610)|[![Github stars](https://img.shields.io/github/stars/JiawangBian/SC-SfMLearner-Release.svg)](https://github.com/JiawangBian/SC-SfMLearner-Release)<br>[![Github stars](https://img.shields.io/github/stars/JiawangBian/sc_depth_pl.svg)](https://github.com/JiawangBian/sc_depth_pl)|---|
|2019|`NIPS`|[Unsupervised scale-consistent depth and ego-motion learning from monocular video](https://proceedings.neurips.cc/paper/2019/file/6364d3f0f495b6ab9dcf8d3b5c6e0b01-Paper.pdf)|[![Github stars](https://img.shields.io/github/stars/JiawangBian/SC-SfMLearner-Release.svg)](https://github.com/JiawangBian/SC-SfMLearner-Release)<br>[![Github stars](https://img.shields.io/github/stars/JiawangBian/sc_depth_pl.svg)](https://github.com/JiawangBian/sc_depth_pl)|---|
|2019|`ICRA`|[Ganvo: Unsupervised deep monocular visual odometry and depth estimation with generative adversarial networks](https://arxiv.org/pdf/1809.05786)|---|---|
|2019|`CVPR`|[Recurrent neural network for (un-) supervised learning of monocular video visual odometry and depth](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Recurrent_Neural_Network_for_Un-Supervised_Learning_of_Monocular_Video_Visual_CVPR_2019_paper.pdf)|-|-| 
|2019|`ICRA`|[Pose graph optimization for unsupervised monocular visual odometry](https://arxiv.org/pdf/1903.06315)|---|---|
|2018|`CVPR`|[Unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhan_Unsupervised_Learning_of_CVPR_2018_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/Huangying-Zhan/Depth-VO-Feat.svg)](https://github.com/Huangying-Zhan/Depth-VO-Feat)|---|
|2018|`ICRA`|[Undeepvo: Monocular visual odometry through unsupervised deep learning](https://arxiv.org/pdf/1709.06841)|-|[website](https://senwang.gitlab.io/UnDeepVO/)|
|2017|`ICRA`|[Deepvo: Towards end-to-end visual odometry with deep recurrent convolutional neural networks](https://arxiv.org/pdf/1709.08429)|-|[website](https://senwang.gitlab.io/DeepVO/)|
|2017|`CVPR`|[Unsupervised learning of depth and ego-motion from video](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Unsupervised_Learning_of_CVPR_2017_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/tinghuiz/SfMLearner.svg)](https://github.com/tinghuiz/SfMLearner)|---|


## Learning-based VIO

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2024|`arXiv`|[SF-Loc: A Visual Mapping and Geo-Localization System based on Sparse Visual Structure Frames](https://arxiv.org/pdf/2412.01500)|[![Github stars](https://img.shields.io/github/stars/GREAT-WHU/SF-Loc.svg)](https://github.com/GREAT-WHU/SF-Loc)|[test](https://kwanwaipang.github.io/SF-Loc/)|
|2024|`arXiv`|[DEIO: Deep Event Inertial Odometry](https://arxiv.org/pdf/2411.03928)|[![Github stars](https://img.shields.io/github/stars/arclab-hku/DEIO.svg)](https://github.com/arclab-hku/DEIO)|[website](https://kwanwaipang.github.io/DEIO/)|
|2024|`CVPR`|[Adaptive vio: Deep visual-inertial odometry with online continual learning](https://openaccess.thecvf.com/content/CVPR2024/papers/Pan_Adaptive_VIO_Deep_Visual-Inertial_Odometry_with_Online_Continual_Learning_CVPR_2024_paper.pdf)|---|---|
|2024|`RAL`|[DBA-Fusion: Tightly Integrating Deep Dense Visual Bundle Adjustment with Multiple Sensors for Large-Scale Localization and Mapping](https://arxiv.org/pdf/2403.13714)|[![Github stars](https://img.shields.io/github/stars/GREAT-WHU/DBA-Fusion.svg)](https://github.com/GREAT-WHU/DBA-Fusion)|---|
|2024|`ICRA`|[DVI-SLAM: A dual visual inertial SLAM network](https://arxiv.org/pdf/2309.13814)|---|---|
|2023|`ICRA`|[Bamf-slam: bundle adjusted multi-fisheye visual-inertial slam using recurrent field transforms](https://arxiv.org/pdf/2306.01173)|---|---|
|2022|`ECCV`|[Efficient deep visual and inertial odometry with adaptive visual modality selection](https://arxiv.org/pdf/2205.06187)|[![Github stars](https://img.shields.io/github/stars/mingyuyng/Visual-Selective-VIO.svg)](https://github.com/mingyuyng/Visual-Selective-VIO)|---|
|2019|`CVPR`|[Selective sensor fusion for neural visual-inertial odometry](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Selective_Sensor_Fusion_for_Neural_Visual-Inertial_Odometry_CVPR_2019_paper.pdf)|---|---|
|2019|`IROS`|[Deepvio: Self-supervised deep learning of monocular visual inertial odometry using 3d geometric constraints](https://arxiv.org/pdf/1906.11435)|---|---| 
|2017|`AAAI`|[Vinet: Visual-inertial odometry as a sequence-to-sequence learning problem](https://arxiv.org/pdf/1701.08376)|[![Github stars](https://img.shields.io/github/stars/HTLife/VINet.svg)](https://github.com/HTLife/VINet)|non-official implementation|


## Learning-based IO

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->
| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[AirIO: Learning Inertial Odometry with Enhanced IMU Feature Observability](https://arxiv.org/pdf/2501.15659)|[![Github stars](https://img.shields.io/github/stars/Air-IO/Air-IO.svg)](https://github.com/Air-IO/Air-IO)|[website](https://air-io.github.io/)<br>[Test](https://kwanwaipang.github.io/AirIO/)|
*|2024|`TIV`|[Deep learning for inertial positioning: A survey](https://arxiv.org/pdf/2303.03757)|---|---|
|2023|`arXiv`|[AirIMU: Learning uncertainty propagation for inertial odometry](https://arxiv.org/pdf/2310.04874)|[![Github stars](https://img.shields.io/github/stars/haleqiu/AirIMU.svg)](https://github.com/haleqiu/AirIMU)|[website](https://airimu.github.io/)<br>[Test](https://kwanwaipang.github.io/AirIMU/)|
|2023|`RAL`|[Learned inertial odometry for autonomous drone racing](https://arxiv.org/pdf/2210.15287)|[![Github stars](https://img.shields.io/github/stars/uzh-rpg/learned_inertial_model_odometry.svg)](https://github.com/uzh-rpg/learned_inertial_model_odometry)|---|
|2022|`ICRA`|[Improved state propagation through AI-based pre-processing and down-sampling of high-speed inertial data](https://www.aau.at/wp-content/uploads/2022/03/imu_preprocessing.pdf)|---|---|
|2022|`RAL`|[Deep IMU Bias Inference for Robust Visual-Inertial Odometry with Factor Graphs](https://arxiv.org/pdf/2211.04517)|---|---|
|2021|`ICRA`|[IMU Data Processing For Inertial Aided Navigation:A Recurrent Neural Network Based Approach](https://arxiv.org/pdf/2103.14286)|---|---|



## Other Resource
* [Awesome-Transformer-based-SLAM](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM)



